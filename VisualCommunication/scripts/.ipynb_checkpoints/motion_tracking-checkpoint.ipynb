{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd492416-915f-41ee-9695-443f1fdc062f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following folder is set as the output folder where all the pose time series are stored\n",
      "C:\\Research_Projects\\repo_vicom_research_colloquium2024\\processed_data\n",
      "\n",
      " The following folder is set as the output folder for saving the masked videos \n",
      "C:\\Research_Projects\\repo_vicom_research_colloquium2024\\masked_videos\n",
      "\n",
      " The following video(s) will be processed for masking: \n",
      "['01_b_P16.mp4', '02_a_P8.mp4', '09_a_P7.mp4', '17_a_P15.mp4', '21_b_P12.mp4', '25_a_P15.mp4', '34_a_P12.mp4', '34_b_P17.mp4']\n"
     ]
    }
   ],
   "source": [
    "#load in required packages\n",
    "import mediapipe as mp #mediapipe\n",
    "import cv2 #opencv\n",
    "import math #basic operations\n",
    "import numpy as np #basic operations\n",
    "import pandas as pd #data wrangling\n",
    "import csv #csv saving\n",
    "import os #some basic functions for inspecting folder structure etc.\n",
    "\n",
    "#list all videos in input_videofolder\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "#time series output folder\n",
    "inputfol = \"../raw_videos/\"\n",
    "vfiles = [f for f in listdir(inputfol) if isfile(join(inputfol, f))] #loop through the filenames and collect them in a list\n",
    "outputf_mask = \"../masked_videos/\"\n",
    "outtputf_ts = \"../processed_data/\"\n",
    "\n",
    "#check videos to be processed\n",
    "print(\"The following folder is set as the output folder where all the pose time series are stored\")\n",
    "print(os.path.abspath(outtputf_ts))\n",
    "print(\"\\n The following folder is set as the output folder for saving the masked videos \")\n",
    "print(os.path.abspath(outputf_mask))\n",
    "print(\"\\n The following video(s) will be processed for masking: \")\n",
    "print(vfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99608775-f4bd-478a-8d43-5414d2bac0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that we have the following number of pose keypoints for markers body\n",
      "33\n",
      "\n",
      " Note that we have the following number of pose keypoints for markers hands\n",
      "42\n",
      "\n",
      " Note that we have the following number of pose keypoints for markers face\n",
      "478\n"
     ]
    }
   ],
   "source": [
    "#initialize modules and functions\n",
    "\n",
    "#load in mediapipe modules\n",
    "mp_holistic = mp.solutions.holistic\n",
    "# Import drawing_utils and drawing_styles.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "##################FUNCTIONS AND OTHER VARIABLES\n",
    "#landmarks 33x that are used by Mediapipe (Blazepose)\n",
    "markersbody = ['NOSE', 'LEFT_EYE_INNER', 'LEFT_EYE', 'LEFT_EYE_OUTER', 'RIGHT_EYE_OUTER', 'RIGHT_EYE', 'RIGHT_EYE_OUTER',\n",
    "          'LEFT_EAR', 'RIGHT_EAR', 'MOUTH_LEFT', 'MOUTH_RIGHT', 'LEFT_SHOULDER', 'RIGHT_SHOULDER', 'LEFT_ELBOW', \n",
    "          'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST', 'LEFT_PINKY', 'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX',\n",
    "          'LEFT_THUMB', 'RIGHT_THUMB', 'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE', 'LEFT_ANKLE', 'RIGHT_ANKLE',\n",
    "          'LEFT_HEEL', 'RIGHT_HEEL', 'LEFT_FOOT_INDEX', 'RIGHT_FOOT_INDEX']\n",
    "\n",
    "markershands = ['LEFT_WRIST', 'LEFT_THUMB_CMC', 'LEFT_THUMB_MCP', 'LEFT_THUMB_IP', 'LEFT_THUMB_TIP', 'LEFT_INDEX_FINGER_MCP',\n",
    "              'LEFT_INDEX_FINGER_PIP', 'LEFT_INDEX_FINGER_DIP', 'LEFT_INDEX_FINGER_TIP', 'LEFT_MIDDLE_FINGER_MCP', \n",
    "               'LEFT_MIDDLE_FINGER_PIP', 'LEFT_MIDDLE_FINGER_DIP', 'LEFT_MIDDLE_FINGER_TIP', 'LEFT_RING_FINGER_MCP', \n",
    "               'LEFT_RING_FINGER_PIP', 'LEFT_RING_FINGER_DIP', 'LEFT_RING_FINGER_TIP', 'LEFT_PINKY_FINGER_MCP', \n",
    "               'LEFT_PINKY_FINGER_PIP', 'LEFT_PINKY_FINGER_DIP', 'LEFT_PINKY_FINGER_TIP',\n",
    "              'RIGHT_WRIST', 'RIGHT_THUMB_CMC', 'RIGHT_THUMB_MCP', 'RIGHT_THUMB_IP', 'RIGHT_THUMB_TIP', 'RIGHT_INDEX_FINGER_MCP',\n",
    "              'RIGHT_INDEX_FINGER_PIP', 'RIGHT_INDEX_FINGER_DIP', 'RIGHT_INDEX_FINGER_TIP', 'RIGHT_MIDDLE_FINGER_MCP', \n",
    "               'RIGHT_MIDDLE_FINGER_PIP', 'RIGHT_MIDDLE_FINGER_DIP', 'RIGHT_MIDDLE_FINGER_TIP', 'RIGHT_RING_FINGER_MCP', \n",
    "               'RIGHT_RING_FINGER_PIP', 'RIGHT_RING_FINGER_DIP', 'RIGHT_RING_FINGER_TIP', 'RIGHT_PINKY_FINGER_MCP', \n",
    "               'RIGHT_PINKY_FINGER_PIP', 'RIGHT_PINKY_FINGER_DIP', 'RIGHT_PINKY_FINGER_TIP']\n",
    "facemarks = [str(x) for x in range(478)] #there are 478 points for the face mesh (see google holistic face mesh info for landmarks)\n",
    "\n",
    "print(\"Note that we have the following number of pose keypoints for markers body\")\n",
    "print(len(markersbody))\n",
    "\n",
    "print(\"\\n Note that we have the following number of pose keypoints for markers hands\")\n",
    "print(len(markershands))\n",
    "\n",
    "print(\"\\n Note that we have the following number of pose keypoints for markers face\")\n",
    "print(len(facemarks ))\n",
    "\n",
    "#set up the column names and objects for the time series data (add time as the first variable)\n",
    "markerxyzbody = ['time']\n",
    "markerxyzhands = ['time']\n",
    "markerxyzface = ['time']\n",
    "\n",
    "for mark in markersbody:\n",
    "    for pos in ['X', 'Y', 'Z', 'visibility']: #for markers of the body you also have a visibility reliability score\n",
    "        nm = pos + \"_\" + mark\n",
    "        markerxyzbody.append(nm)\n",
    "for mark in markershands:\n",
    "    for pos in ['X', 'Y', 'Z']:\n",
    "        nm = pos + \"_\" + mark\n",
    "        markerxyzhands.append(nm)\n",
    "for mark in facemarks:\n",
    "    for pos in ['X', 'Y', 'Z']:\n",
    "        nm = pos + \"_\" + mark\n",
    "        markerxyzface.append(nm)\n",
    "\n",
    "#check if there are numbers in a string\n",
    "def num_there(s):\n",
    "    return any(i.isdigit() for i in s)\n",
    "\n",
    "#take some google classification object and convert it into a string\n",
    "def makegoginto_str(gogobj):\n",
    "    gogobj = str(gogobj).strip(\"[]\")\n",
    "    gogobj = gogobj.split(\"\\n\")\n",
    "    return(gogobj[:-1]) #ignore last element as this has nothing\n",
    "\n",
    "#make the stringifyd position traces into clean numerical values\n",
    "def listpostions(newsamplemarks):\n",
    "    newsamplemarks = makegoginto_str(newsamplemarks)\n",
    "    tracking_p = []\n",
    "    for value in newsamplemarks:\n",
    "        if num_there(value):\n",
    "            stripped = value.split(':', 1)[1]\n",
    "            stripped = stripped.strip() #remove spaces in the string if present\n",
    "            tracking_p.append(stripped) #add to this list  \n",
    "    return(tracking_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9078c331-8d21-49c7-b2ab-aa53c96f0f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will now process video:\n",
      "01_b_P16.mp4\n",
      "This is video number0of8videos in total\n",
      "We will now process video:\n",
      "02_a_P8.mp4\n",
      "This is video number1of8videos in total\n",
      "We will now process video:\n",
      "09_a_P7.mp4\n",
      "This is video number2of8videos in total\n",
      "We will now process video:\n",
      "17_a_P15.mp4\n",
      "This is video number3of8videos in total\n",
      "We will now process video:\n",
      "21_b_P12.mp4\n",
      "This is video number4of8videos in total\n",
      "We will now process video:\n",
      "25_a_P15.mp4\n",
      "This is video number5of8videos in total\n",
      "We will now process video:\n",
      "34_a_P12.mp4\n",
      "This is video number6of8videos in total\n",
      "We will now process video:\n",
      "34_b_P17.mp4\n",
      "This is video number7of8videos in total\n",
      "Done with processing all folders; go look in your output folders!\n"
     ]
    }
   ],
   "source": [
    "# do you want to apply masking?\n",
    "masking = True\n",
    "\n",
    "#We will now loop over all the videos that are present in the video file\n",
    "for vidf in vfiles:\n",
    "    print(\"We will now process video:\")\n",
    "    print(vidf)\n",
    "    print(\"This is video number\" + str(vfiles.index(vidf))+ \"of\" + str(len(vfiles)) + \"videos in total\")\n",
    "    #capture the video, and check video settings\n",
    "    videoname = vidf\n",
    "    videoloc = inputfol + videoname\n",
    "    capture = cv2.VideoCapture(videoloc) #load in the videocapture\n",
    "    frameWidth = capture.get(cv2.CAP_PROP_FRAME_WIDTH) #check frame width\n",
    "    frameHeight = capture.get(cv2.CAP_PROP_FRAME_HEIGHT) #check frame height\n",
    "    samplerate = capture.get(cv2.CAP_PROP_FPS)   #fps = frames per second\n",
    "\n",
    "    #make an 'empty' video file where we project the pose tracking on\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V') #for different video formats you could use e.g., *'XVID'\n",
    "    out = cv2.VideoWriter(outputf_mask+videoname, fourcc, \n",
    "                          fps = samplerate, frameSize = (int(frameWidth), int(frameHeight)))\n",
    "\n",
    "    # Run MediaPipe frame by frame using Holistic with `enable_segmentation=True` to get pose segmentation.\n",
    "    time = 0\n",
    "    tsbody = [markerxyzbody]   #these will be your time series objects, which start with collumn names initialized above\n",
    "    tshands = [markerxyzhands] #these will be your time series objects, which start with collumn names initialized above\n",
    "    tsface = [markerxyzface]   #these will be your time series objects, which start with collumn names initialized above\n",
    "    with mp_holistic.Holistic(\n",
    "            static_image_mode=False, enable_segmentation=True, refine_face_landmarks=True) as holistic:\n",
    "        while (True):\n",
    "            ret, image = capture.read() #read frame\n",
    "            if ret == True: #if there is a frame\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #make sure the image is in RGB format\n",
    "                results = holistic.process(image) #apply Mediapipe holistic processing\n",
    "                # Draw pose segmentation\n",
    "                h, w, c = image.shape\n",
    "                if  np.all(results.segmentation_mask) != None: #check if there is a pose found\n",
    "                    if masking == False:\n",
    "                        original_image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                    if masking == True:\n",
    "                        original_image = np.concatenate([image, np.full((h, w, 1), 255, dtype=np.uint8)], axis=-1)\n",
    "                        mask_img = np.zeros_like(image, dtype=np.uint8) #set up basic mask image\n",
    "                        mask_img[:, :] = (255,255,255) #set up basic mask image\n",
    "                        segm_2class = 0.2 + 0.8 * results.segmentation_mask #set up a segmentation of the results of mediapipe\n",
    "                        segm_2class = np.repeat(segm_2class[..., np.newaxis], 3, axis=2) #set up a segmentation of the results of mediapipe\n",
    "                        annotated_image = mask_img * segm_2class * (1 - segm_2class) #take the basic mask image and make a sillhouette mask\n",
    "                        # append Alpha channel to sillhouetted mask so that we can overlay it to the original image\n",
    "                        mask = np.concatenate([annotated_image, np.full((h, w, 1), 255, dtype=np.uint8)], axis=-1)\n",
    "                        # Zero background where we want to overlay\n",
    "                        original_image[mask==0]=0 #for the original image we are going to set everything at zero for places where the mask has to go\n",
    "                        original_image = cv2.cvtColor(original_image, cv2.COLOR_RGB2BGR)\n",
    "                    #now lets draw on the original_image the left and right hand landmarks, the facemesh and the body poses\n",
    "                        #left hand\n",
    "                    mp_drawing.draw_landmarks(original_image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "                        #right hand\n",
    "                    mp_drawing.draw_landmarks(original_image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "                        #face\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                            original_image,\n",
    "                            results.face_landmarks,\n",
    "                            mp_holistic.FACEMESH_TESSELATION,\n",
    "                            landmark_drawing_spec=None,\n",
    "                            connection_drawing_spec=mp_drawing_styles\n",
    "                            .get_default_face_mesh_tesselation_style())\n",
    "                        #body (lets no draw the body, so that we can see the facemesh better)\n",
    "                    #mp_drawing.draw_landmarks(\n",
    "                    #        original_image,\n",
    "                    #        results.pose_landmarks,\n",
    "                    #        mp_holistic.POSE_CONNECTIONS,\n",
    "                    #        landmark_drawing_spec=mp_drawing_styles.\n",
    "                    #        get_default_pose_landmarks_style())\n",
    "                    #######################now save everything to a time series\n",
    "                        #make a variable list with x, y, z, info where data is appended to\n",
    "                    samplebody = listpostions(results.pose_world_landmarks) # we are saving it in body centered estimates in real world coordinates (meters)\n",
    "                    samplehands = listpostions([results.left_hand_landmarks, results.right_hand_landmarks])\n",
    "                    sampleface = listpostions(results.face_landmarks)\n",
    "                    samplebody.insert(0, time)\n",
    "                    samplehands.insert(0, time)\n",
    "                    sampleface.insert(0, time)\n",
    "                    tsbody.append(samplebody)   #append to the timeseries object\n",
    "                    tshands.append(samplehands) #append to the timeseries object\n",
    "                    tsface.append(sampleface)   #append to the timeseries object\n",
    "                #show the video as we process (you can comment this out, if you want to run this process in the background)\n",
    "                cv2.imshow(\"resizedimage\", original_image)\n",
    "                out.write(original_image) #save the frame to the new masked video\n",
    "                time = time+(1000/samplerate)#update the time variable  for the next frame\n",
    "            if cv2.waitKey(1) == 27: #allow the use of ESCAPE to break the loop\n",
    "                   break\n",
    "            if ret == False: #if there are no more frames, break the loop\n",
    "                break\n",
    "\n",
    "    #once done de-initialize all processes\n",
    "    out.release()\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "     ####################################################### data to be written row-wise in csv fil\n",
    "    # opening the csv file in 'w+' mode\n",
    "    filebody = open(outtputf_ts + vidf[:-4]+'_body.csv', 'w+', newline ='')\n",
    "    #write it\n",
    "    with filebody:    \n",
    "        write = csv.writer(filebody)\n",
    "        write.writerows(tsbody)\n",
    "     # opening the csv file in 'w+' mode\n",
    "    filehands = open(outtputf_ts + vidf[:-4]+'_hands.csv', 'w+', newline ='')\n",
    "    #write it\n",
    "    with filehands:\n",
    "        write = csv.writer(filehands)\n",
    "        write.writerows(tshands)\n",
    "    # opening the csv file in 'w+' mode\n",
    "    fileface = open(outtputf_ts + vidf[:-4]+'_face.csv', 'w+', newline ='')\n",
    "    #write it\n",
    "    with fileface:    \n",
    "        write = csv.writer(fileface)\n",
    "        write.writerows(tsface)\n",
    "\n",
    "print(\"Done with processing all folders; go look in your output folders!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a6a73eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will now process video:\n",
      "01_b_P16.mp4\n",
      "This is video number0of8videos in total\n",
      "25.0\n",
      "Moviepy - Building video ../masked_videos/alt01_b_P16.mp4.\n",
      "Moviepy - Writing video ../masked_videos/alt01_b_P16.mp4\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17016\\2649685703.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideoloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_videofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputf_mask\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'alt'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvideoname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcodec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'libx264'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36mrequires_duration\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Attribute 'duration' not set\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36muse_clip_fps_by_default\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m    133\u001b[0m              for (k,v) in k.items()}\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36mconvert_masks_to_RGB\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismask\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_RGB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36mwrite_videofile\u001b[1;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[0;32m    298\u001b[0m                                        logger=logger)\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         ffmpeg_write_video(self, filename, fps, codec,\n\u001b[0m\u001b[0;32m    301\u001b[0m                            \u001b[0mbitrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbitrate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                            \u001b[0mpreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_writer.py\u001b[0m in \u001b[0;36mffmpeg_write_video\u001b[1;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mlogfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Moviepy - Writing video %s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m     with FFMPEG_VideoWriter(filename, clip.size, fps, codec = codec,\n\u001b[0m\u001b[0;32m    214\u001b[0m                                 \u001b[0mpreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbitrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbitrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                                 \u001b[0maudiofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maudiofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, size, fps, codec, audiofile, preset, bitrate, withmask, logfile, threads, ffmpeg_params)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;34m'-s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%dx%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;34m'-pix_fmt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rgba'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mwithmask\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'rgb24'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;34m'-r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%.02f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;34m'-an'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-i'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         ]\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "# since opencv has some issues with video writing, we will convert them to a new video using moviepy\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import Video\n",
    "#list all videos in input_videofolder\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "vfiles = [f for f in listdir(outputf_mask ) if isfile(join(outputf_mask , f))] #loop through the filenames and collect them in a list\n",
    "\n",
    "# now load these videos and write them to a new video\n",
    "for vidf in vfiles:\n",
    "    print(\"We will now process video:\")\n",
    "    print(vidf)\n",
    "    print(\"This is video number\" + str(vfiles.index(vidf))+ \"of\" + str(len(vfiles)) + \"videos in total\")\n",
    "    videoname = vidf\n",
    "    videoloc = outputf_mask  + videoname\n",
    "    clip = VideoFileClip(videoloc)\n",
    "    print(clip.fps)\n",
    "    clip.write_videofile(outputf_mask + 'alt' + videoname, codec='libx264', fps=float(clip.fps))\n",
    "    clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "290ad9d8-99d2-4319-ac86-2864c805a412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: 01_b_P16.mp4\n",
      "This is video 1 of 8\n",
      "Processing video: 02_a_P8.mp4\n",
      "This is video 2 of 8\n",
      "Processing video: 09_a_P7.mp4\n",
      "This is video 3 of 8\n",
      "Processing video: 17_a_P15.mp4\n",
      "This is video 4 of 8\n",
      "Processing video: 21_b_P12.mp4\n",
      "This is video 5 of 8\n",
      "Processing video: 25_a_P15.mp4\n",
      "This is video 6 of 8\n",
      "Processing video: 34_a_P12.mp4\n",
      "This is video 7 of 8\n",
      "Processing video: 34_b_P17.mp4\n",
      "This is video 8 of 8\n",
      "Video processing complete.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# List all videos in the output folder\n",
    "vfiles = [f for f in listdir(outputf_mask) if isfile(join(outputf_mask, f))]\n",
    "\n",
    "# Process each video file\n",
    "for vidf in vfiles:\n",
    "    print(\"Processing video:\", vidf)\n",
    "    print(\"This is video\", vfiles.index(vidf) + 1, \"of\", len(vfiles))\n",
    "    \n",
    "    # Input and output file paths\n",
    "    input_file = outputf_mask + vidf\n",
    "    output_file = outputf_mask + 'alt_' + vidf\n",
    "    \n",
    "    # Run ffmpeg command to encode the video\n",
    "    command = ['ffmpeg', '-i', input_file, '-c:v', 'libx264', '-preset', 'fast', output_file]\n",
    "    subprocess.run(command)\n",
    "\n",
    "print(\"Video processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75cc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
